{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import keras\n",
    "import random\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "print(\"Tensorflow version: \",tf.__version__)\n",
    "print(\"Keras version: \",keras.__version__)\n",
    "sklearn.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5 #50%GPU shared memory\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING THE IMAGES\n",
    "def Preprocessing_Banana(n):\n",
    "\n",
    "    gray=cv2.cvtColor(n, cv2.COLOR_BGR2GRAY ) #rgb to gray\n",
    "    setting_size=100 #Resize the image\n",
    "    resized_img=cv2.resize(gray,(setting_size,setting_size))\n",
    "    histequ = cv2.equalizeHist(resized_img) #doing histogram equalisation\n",
    "    gb=cv2.medianBlur(histequ,5) #noise removal using gaussian blur for smoothing the image\n",
    "    gx = cv2.Sobel(gb, cv2.CV_16S, 1, 0, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT) #Image segmentation for edge detection\n",
    "    gy = cv2.Sobel(gb, cv2.CV_16S, 0, 1, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT) #Image segmentation for edge detection\n",
    "    ax = cv2.convertScaleAbs(gx)\n",
    "    ay = cv2.convertScaleAbs(gy)\n",
    "    edge = cv2.addWeighted(ax, 0.5, ay, 0.5, 0) #sobel derivative\n",
    "    clean_data =edge\n",
    "    return clean_data\n",
    "\n",
    "dir1=\"C:\\\\Users\\\\pavit\\\\Downloads\\\\train\"\n",
    "catg=['C','H', 'P', 'S']\n",
    "\n",
    "\n",
    "img_cube=[]\n",
    "image_size=800\n",
    "\n",
    "for i in catg: #this will take the folder names as we call it as categoris\n",
    "    path=os.path.join(dir1,i) #location\n",
    "    label=catg.index(i) #C=0, H=1 and so on\n",
    "    for j in os.listdir(path): #this will take the actual path of each folder image\n",
    "        img_arr=cv2.imread(os.path.join(path,j)) #convert rgb image to gray scale image\n",
    "        final_data=Img_preprocessing(img_arr)\n",
    "        img_cube.append([final_data,label])\n",
    "print(\"Length of your dataset: \",len(img_cube))\n",
    "print(\"Whole image data in array format:\\n\",img_cube[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=[]\n",
    "target=[]\n",
    "for i in img_cube:\n",
    "    flat=i[0].flatten() #Image is 2d so flattening it. making it 1d.\n",
    "    feature.append(flat)\n",
    "for i in img_cube:\n",
    "    target.append(i[1]) #Category\n",
    "    \n",
    "len(feature),len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSIFIERS WITH PREPROCESSING\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(feature,target,test_size=0.25,random_state=40)\n",
    "\n",
    "csv=SVC().fit(x_train,y_train) #Parameters check. Since we flattened accuracy less. Assumes inputs as vectors. CNN Uses 2D\n",
    "y_pred=csv.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "dtc = DecisionTreeClassifier().fit(x_train,y_train)\n",
    "y_preded=dtc.predict(x_test)\n",
    "print(accuracy_score(y_test,y_preded)*100)\n",
    "\n",
    "neww = KNeighborsClassifier().fit(x_train,y_train)\n",
    "y_prededed=neww.predict(x_test)\n",
    "print(accuracy_score(y_test,y_prededed)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSIFIERS WITHOUT PREPROCESSING\n",
    "dir2=\"C:\\\\Users\\\\pavit\\\\Downloads\\\\train\"\n",
    "catg=['C','H', 'P', 'S']\n",
    "\n",
    "\n",
    "img_cube2=[]\n",
    "image_size=500\n",
    "\n",
    "for i in catg: #this will take the folder names as we call it as categoris\n",
    "    path=os.path.join(dir2,i)\n",
    "    label=catg.index(i)\n",
    "    for j in os.listdir(path): #this will take the actual path of each folder image\n",
    "        img_arr=cv2.imread(os.path.join(path,j))\n",
    "        gray=cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY )\n",
    "        resized_img=cv2.resize(gray,(200,200))\n",
    "        img_cube2.append([resized_img,label])\n",
    "\n",
    "random.shuffle(img_cube2)\n",
    "\n",
    "feature2=[]\n",
    "target2=[]\n",
    "for i in img_cube2:\n",
    "    flat=i[0].flatten()\n",
    "    feature2.append(flat)\n",
    "for i in img_cube2:\n",
    "    target2.append(i[1])\n",
    "\n",
    "\n",
    "x_train2,x_test2,y_train2,y_test2=train_test_split(feature2,target2,test_size=0.25,random_state=40)\n",
    "\n",
    "cl=SVC().fit(x_train2,y_train2)\n",
    "y_pred2=cl.predict(x_test2)\n",
    "print(accuracy_score(y_test2,y_pred2)*100)\n",
    "\n",
    "dc = DecisionTreeClassifier().fit(x_train2,y_train2)\n",
    "y_preded2=dc.predict(x_test2)\n",
    "print(accuracy_score(y_test2,y_preded2)*100)\n",
    "\n",
    "newww = KNeighborsClassifier().fit(x_train2,y_train2)\n",
    "y_prededed2=newww.predict(x_test2)\n",
    "print(accuracy_score(y_test2,y_prededed2)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSIFIERS WITH COLOUR\n",
    "\n",
    "img_cube2=[]\n",
    "image_size=500\n",
    "\n",
    "for i in catg: #this will take the folder names as we call it as categoris\n",
    "    path=os.path.join(dir2,i)\n",
    "    label=catg.index(i)\n",
    "    for j in os.listdir(path): #this will take the actual path of each folder image\n",
    "        img_arr=cv2.imread(os.path.join(path,j))\n",
    "        resized_img=cv2.resize(img_arr,(200,200))\n",
    "        img_cube2.append([resized_img,label])\n",
    "\n",
    "random.shuffle(img_cube2)\n",
    "\n",
    "feature2=[]\n",
    "target2=[]\n",
    "for i in img_cube2:\n",
    "    flat=i[0].flatten()\n",
    "    feature2.append(flat)\n",
    "for i in img_cube2:\n",
    "    target2.append(i[1])\n",
    "feature2 = np.array(feature2)/ 255.0\n",
    "\n",
    "x_train2,x_test2,y_train2,y_test2=train_test_split(feature2,target2,test_size=0.25,random_state=42)\n",
    "\n",
    "clf=SVC().fit(x_train2,y_train2)\n",
    "y_pred3=clf.predict(x_test2)\n",
    "print(accuracy_score(y_test2,y_pred3)*100)\n",
    "\n",
    "clfd = DecisionTreeClassifier().fit(x_train2,y_train2)\n",
    "y_preded3=clfd.predict(x_test2)\n",
    "print(accuracy_score(y_test2,y_preded3)*100)\n",
    "\n",
    "newwww = KNeighborsClassifier().fit(x_train2,y_train2)\n",
    "y_prededed3=newwww.predict(x_test2)\n",
    "print(accuracy_score(y_test2,y_prededed3)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK TENSORFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "# Preprocessing the Training set\n",
    "training_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = training_datagen.flow_from_directory('Downloads/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',subset=\"training\")\n",
    "# Preprocessing the Test set\n",
    "testing_datagen = ImageDataGenerator(rescale = 1./255, validation_split=0.9)\n",
    "test_set = testing_datagen.flow_from_directory('Downloads/test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical',subset=\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense #add nodes\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Building the CNN\n",
    "# Initialising the CNN\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3, activation='relu', strides=2, input_shape=[64, 64, 3]))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Adding a third convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Step 4 - Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# Step 5 - Output Layer\n",
    "cnn.add(tf.keras.layers.Dense(units=4, activation='sigmoid'))\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the CNN on the Training set and evaluating it on the Test set\n",
    "r=cnn.fit(x = training_set, validation_data = test_set, epochs = 100, verbose=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(\"final_mod.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYBRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense #add nodes\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# Importing the libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING SVM IN CNN: RCNN\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5 #50%GPU shared memory\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "# Preprocessing the Training set\n",
    "training_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training_datagen.flow_from_directory('Downloads/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',subset=\"training\")\n",
    "# Preprocessing the Test set\n",
    "testing_datagen = ImageDataGenerator(rescale = 1./255, validation_split=0.9)\n",
    "test_set = testing_datagen.flow_from_directory('Downloads/test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical',subset=\"validation\")\n",
    "#Question: Why didnt you use image train_datagen for the test as well? Why no augmentation in test apart from rescale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Building the CNN\n",
    "# Initialising the CNN\n",
    "cnn = tf.keras.models.Sequential() \n",
    "\n",
    "# Step 1 - Convolution \n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3, activation='relu', strides=2, input_shape=[64, 64, 3]))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) #as 2D image\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Step 4 - Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output and Compiler (SVM)\n",
    "cnn.add(Dense(4, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation ='softmax'))  #l2 norm and can be 0.001 also\n",
    "cnn.compile(optimizer = 'adam', loss = 'squared_hinge', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Training the CNN\n",
    "# Training the CNN on the Training set and evaluating it on the Test set\n",
    "r=cnn.fit(x = training_set, validation_data = test_set, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(\"hybrid.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
